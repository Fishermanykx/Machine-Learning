{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 题目\n",
    "* 利用鸢尾花卉数据集，利用LDA算法实现3分类问题，可以用一对一（0v0）也可以用一对多（OvR）。\n",
    "* 鸢尾花：数据集包含150个数据样本，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。\n",
    "* 实现：对数据集进行划分（训练集测试集），实现测试集准确的分类，并可视化结果，同时和sklearn结果进行对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1、Describe of iris dataset:\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, pre\n",
      "...\n",
      "\n",
      "2、Target names of iris dataset:\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "3、Feature names of iris dataset:\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "dataset_iris = datasets.load_iris()\n",
    "print('\\n1、Describe of iris dataset:\\n{}'.format(dataset_iris['DESCR'][:193] + '\\n...'))\n",
    "print('\\n2、Target names of iris dataset:\\n{}'.format(dataset_iris.target_names))\n",
    "print('\\n3、Feature names of iris dataset:\\n{}'.format(dataset_iris.feature_names))\n",
    "\n",
    "X = dataset_iris.data\n",
    "y = dataset_iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA():\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def calculate_covariance_matrix(self, X, Y=None):\n",
    "        # 计算协方差矩阵\n",
    "        m = X.shape[0]\n",
    "        X = X - np.mean(X, axis=0)\n",
    "        Y = X if Y == None else Y - np.mean(Y, axis=0)\n",
    "        return 1 / m * np.matmul(X.T, Y)\n",
    "\n",
    "    #LDA拟合过程\n",
    "    def fit(self,X,y):\n",
    "        # 按类划分\n",
    "        X0 = X[y.reshape(-1) == 0]\n",
    "        X1 = X[y.reshape(-1) == 1]\n",
    "\n",
    "        # 计算两类数据变量的协方差矩阵\n",
    "        sigma0 = self.calculate_covariance_matrix(X0)\n",
    "        sigma1 = self.calculate_covariance_matrix(X1)\n",
    "        # 计算类内散度矩阵\n",
    "        Sw = sigma0 + sigma1\n",
    "\n",
    "        # 分别计算两类数据自变量的均值和方差\n",
    "        u0, u1 = X0.mean(0), X1.mean(0)\n",
    "        mean_diff = np.atleast_1d(u0 - u1)  # atleast_1d将输入转换为至少一维的数组\n",
    "        # 对类内矩阵进行奇异值分解\n",
    "        U, S, V = np.linalg.svd(Sw)\n",
    "        # 计算类内散度矩阵的逆\n",
    "        Sw_ = np.dot(np.dot(V, np.linalg.pinv(np.diag(S))), U.T)\n",
    "        # 计算w\n",
    "        self.w = Sw_.dot(mean_diff)\n",
    "        # # 判别权重矩阵\n",
    "        # self.w = np.dot(np.mat(Sw).I, (np.mean(X0, axis=0) - np.mean(X1, axis=0)).reshape((len(np.mean(X0, axis=0)), 1)))\n",
    "        return self.w\n",
    "\n",
    "    #LDA分类预测：\n",
    "    def predict(self,X):\n",
    "        y_pred=[]\n",
    "        for sample in X:\n",
    "            h=sample.dot(self.w)\n",
    "            y=1*(h<0)\n",
    "            y_pred.append(y)\n",
    "        return y_pred\n",
    "\n",
    "    # LDA分类预测：\n",
    "    def class_visu(self,X, y):\n",
    "        X1 = np.array([X[i] for i in range(len(X)) if y[i] == 0])\n",
    "        X2 = np.array([X[i] for i in range(len(X)) if y[i] == 1])\n",
    "\n",
    "        X1_new = np.dot(X1, self.w)  # 向量的点积几何意义：相当于点在投影矩阵上的投影，所以根据求得的投影矩阵w求取新的值\n",
    "        X2_new = np.dot(X2, self.w)\n",
    "\n",
    "        y1_new = [1 for i in range(len(X1))] # 投影后打上新的标签\n",
    "        y2_new = [1 for i in range(len(X2))]\n",
    "\n",
    "        return X1_new, X2_new, y1_new, y2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用OvA策略，三个类别对应三个模型，用字典格式存储\n",
    "def OvR_calss(x_train, y_train):\n",
    "    models = {}\n",
    "    y_train_copy = y_train.copy()\n",
    "    unique_targets = np.unique(y_train_copy, return_index=True, return_counts=True)\n",
    "\n",
    "    for target in unique_targets[0]:\n",
    "        #管道流封装\n",
    "        models[target] = LDA()\n",
    "        y_train_list = y_train_copy.tolist()\n",
    "        # 每次都要修改训练集的标签,将当前类别的标签设为1，其它类别设为0\n",
    "        for i in range(len(y_train_list)):\n",
    "            if y_train_list[i] == target:\n",
    "                y_train_list[i] = 1\n",
    "            else:\n",
    "                y_train_list[i] = 0\n",
    "        y_train = np.array(y_train_list)\n",
    "\n",
    "        models[target].fit(x_train, y_train)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1、Describe of iris dataset:\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, pre\n",
      "...\n",
      "\n",
      "2、Target names of iris dataset:\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "3、Feature names of iris dataset:\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\narray([0, 1, 2])\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "dataset_iris = datasets.load_iris()\n",
    "print('\\n1、Describe of iris dataset:\\n{}'.format(dataset_iris['DESCR'][:193] + '\\n...'))\n",
    "print('\\n2、Target names of iris dataset:\\n{}'.format(dataset_iris.target_names))\n",
    "print('\\n3、Feature names of iris dataset:\\n{}'.format(dataset_iris.feature_names))\n",
    "\n",
    "X = dataset_iris.data\n",
    "y = dataset_iris.target\n",
    "\n",
    "# 数据标准化处理\n",
    "dataset_normalizer = StandardScaler().fit(X)\n",
    "X = dataset_normalizer.transform(X)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X, y, random_state=1)\n",
    "\n",
    "# 只取标签为0的test\n",
    "x_test_0 = x_test[y_test == 0]\n",
    "x_test_1 = x_test[y_test == 1]\n",
    "x_test_2 = x_test[y_test == 2]\n",
    "\n",
    "#获取标签变量的类别\n",
    "unique_targets = np.unique(y, return_index=True, return_counts=True)\n",
    "'''\n",
    "array([0, 1, 2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], 1: [1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1], 2: [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0]}\n",
      "{0: 16, 1: 17, 2: 18}\n",
      "class:2\n"
     ]
    }
   ],
   "source": [
    "test_probs = {}\n",
    "test_class = {}\n",
    "models = OvR_calss(x_train, y_train)\n",
    "for target in unique_targets[0]:\n",
    "    #[:,1]返回的是属于1的概率，[:,0]是属于0的概率\n",
    "    test_probs[target] = models[target].predict(x_test)\n",
    "    test_class[target] = sum(test_probs[target])\n",
    "\n",
    "max_Key = list(test_class.keys())[list(test_class.values()).index(max(list(test_class.values())))]\n",
    "\n",
    "print(test_probs)\n",
    "print(test_class)\n",
    "print(\"class:{}\".format(max_Key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
